{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural network.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "2ym4Sqccn_5I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Simple feed-forward network"
      ]
    },
    {
      "metadata": {
        "id": "d2T6YI8nldXa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aRJNucalyyDP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_hidden = 10\n",
        "n_in = 10\n",
        "n_out = 10\n",
        "n_sample = 300\n",
        "\n",
        "\n",
        "learning_rate = 0.01\n",
        "momentum = 0.9\n",
        "\n",
        "np.random.seed(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8eftOoS-0bB_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh_prime(x):\n",
        "  return 1 - np.tanh(x)**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fM0aTAks1ROJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train (x, t, V, W, bv, bw):\n",
        "  #forward propogation\n",
        "  a = np.dot(x,V) + bv\n",
        "  z = np.tanh(a)\n",
        "  \n",
        "  b = np.dot(z,W) + bw\n",
        "  y = sigmoid(b)\n",
        "  \n",
        "  #backward\n",
        "  Ew = y - t\n",
        "  Ev = tanh_prime(a) * np.dot(W, Ew)\n",
        "  \n",
        "  #predict loss\n",
        "  dw = np.outer(z,Ew)\n",
        "  dv = np.outer(x,Ev)\n",
        "  \n",
        "  #cross entroy\n",
        "  loss = -np.mean(t * np.log(y) + (1 - t) * np.log(1 - y))\n",
        "  \n",
        "  return loss,(dv, dw, Ev, Ew)\n",
        "\n",
        "def predict(x, v, w , bv, bw):\n",
        "  a = np.dot(x, v) + bv\n",
        "  b = np.dot(np.tanh(a), w) + bw\n",
        "  return (sigmoid(b) > 0.5).astype(int)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rocbH4z1VQdI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1747
        },
        "outputId": "ba71ca0f-6aeb-404c-a39f-6b4677232ff9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532709791664,
          "user_tz": -330,
          "elapsed": 2986,
          "user": {
            "displayName": "Shobhit Sundriyal",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "117368682925893777140"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#create the layers\n",
        "v = np.random.normal(scale=0.1, size=(n_in, n_hidden))\n",
        "w = np.random.normal(scale=0.1, size=(n_hidden, n_out))\n",
        "\n",
        "bv = np.zeros(n_hidden)\n",
        "bw = np.zeros(n_out)\n",
        "\n",
        "params = [v, w, bv, bw]\n",
        "\n",
        "x = np.random.binomial(1, 0.5, (n_sample, n_in))\n",
        "t = x ^ 1\n",
        "\n",
        "#training\n",
        "for epoch in range (100):\n",
        "  err = []\n",
        "  update = [0] * len(params)\n",
        "  t0 = time.clock()\n",
        "  \n",
        "  for i in range(x.shape[0]):\n",
        "    loss, grad = train(x[i], t[i], *params)\n",
        "    #update loss\n",
        "    for j in range(len(params)):\n",
        "      params[j] = params[j] - update[j]\n",
        "      \n",
        "    for j in range(len(params)):\n",
        "      update[j] = learning_rate * grad[j] + momentum * update[j]\n",
        "      \n",
        "    err.append(loss)\n",
        "    \n",
        "  print('Epoch:%d, Loss:%.8f, Time:%.4f s'%(epoch, np.mean(err), time.clock()-t0))\n",
        "  \n",
        "#predict\n",
        "p = np.random.binomial(1, 0.5, n_in)\n",
        "print('XOR prediction')\n",
        "print(p)\n",
        "print(predict(p, *params))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0, Loss:0.45618589, Time:0.0218 s\n",
            "Epoch:1, Loss:0.12314877, Time:0.0189 s\n",
            "Epoch:2, Loss:0.05813583, Time:0.0191 s\n",
            "Epoch:3, Loss:0.03643387, Time:0.0187 s\n",
            "Epoch:4, Loss:0.02692332, Time:0.0184 s\n",
            "Epoch:5, Loss:0.02140196, Time:0.0189 s\n",
            "Epoch:6, Loss:0.01767920, Time:0.0187 s\n",
            "Epoch:7, Loss:0.01497205, Time:0.0184 s\n",
            "Epoch:8, Loss:0.01292232, Time:0.0184 s\n",
            "Epoch:9, Loss:0.01131862, Time:0.0186 s\n",
            "Epoch:10, Loss:0.01002721, Time:0.0189 s\n",
            "Epoch:11, Loss:0.00896448, Time:0.0236 s\n",
            "Epoch:12, Loss:0.00807682, Time:0.0185 s\n",
            "Epoch:13, Loss:0.00732768, Time:0.0187 s\n",
            "Epoch:14, Loss:0.00669050, Time:0.0185 s\n",
            "Epoch:15, Loss:0.00614481, Time:0.0190 s\n",
            "Epoch:16, Loss:0.00567425, Time:0.0182 s\n",
            "Epoch:17, Loss:0.00526553, Time:0.0192 s\n",
            "Epoch:18, Loss:0.00490797, Time:0.0186 s\n",
            "Epoch:19, Loss:0.00459300, Time:0.0184 s\n",
            "Epoch:20, Loss:0.00431379, Time:0.0189 s\n",
            "Epoch:21, Loss:0.00406479, Time:0.0186 s\n",
            "Epoch:22, Loss:0.00384154, Time:0.0244 s\n",
            "Epoch:23, Loss:0.00364035, Time:0.0188 s\n",
            "Epoch:24, Loss:0.00345820, Time:0.0183 s\n",
            "Epoch:25, Loss:0.00329258, Time:0.0187 s\n",
            "Epoch:26, Loss:0.00314138, Time:0.0186 s\n",
            "Epoch:27, Loss:0.00300285, Time:0.0195 s\n",
            "Epoch:28, Loss:0.00287548, Time:0.0193 s\n",
            "Epoch:29, Loss:0.00275800, Time:0.0184 s\n",
            "Epoch:30, Loss:0.00264933, Time:0.0184 s\n",
            "Epoch:31, Loss:0.00254854, Time:0.0192 s\n",
            "Epoch:32, Loss:0.00245480, Time:0.0201 s\n",
            "Epoch:33, Loss:0.00236741, Time:0.0256 s\n",
            "Epoch:34, Loss:0.00228577, Time:0.0193 s\n",
            "Epoch:35, Loss:0.00220932, Time:0.0189 s\n",
            "Epoch:36, Loss:0.00213761, Time:0.0187 s\n",
            "Epoch:37, Loss:0.00207020, Time:0.0187 s\n",
            "Epoch:38, Loss:0.00200673, Time:0.0189 s\n",
            "Epoch:39, Loss:0.00194686, Time:0.0187 s\n",
            "Epoch:40, Loss:0.00189031, Time:0.0187 s\n",
            "Epoch:41, Loss:0.00183681, Time:0.0184 s\n",
            "Epoch:42, Loss:0.00178612, Time:0.0186 s\n",
            "Epoch:43, Loss:0.00173803, Time:0.0185 s\n",
            "Epoch:44, Loss:0.00169235, Time:0.0231 s\n",
            "Epoch:45, Loss:0.00164890, Time:0.0183 s\n",
            "Epoch:46, Loss:0.00160753, Time:0.0186 s\n",
            "Epoch:47, Loss:0.00156809, Time:0.0187 s\n",
            "Epoch:48, Loss:0.00153045, Time:0.0188 s\n",
            "Epoch:49, Loss:0.00149449, Time:0.0186 s\n",
            "Epoch:50, Loss:0.00146011, Time:0.0186 s\n",
            "Epoch:51, Loss:0.00142720, Time:0.0185 s\n",
            "Epoch:52, Loss:0.00139568, Time:0.0183 s\n",
            "Epoch:53, Loss:0.00136545, Time:0.0185 s\n",
            "Epoch:54, Loss:0.00133644, Time:0.0187 s\n",
            "Epoch:55, Loss:0.00130859, Time:0.0223 s\n",
            "Epoch:56, Loss:0.00128182, Time:0.0189 s\n",
            "Epoch:57, Loss:0.00125607, Time:0.0191 s\n",
            "Epoch:58, Loss:0.00123128, Time:0.0194 s\n",
            "Epoch:59, Loss:0.00120741, Time:0.0184 s\n",
            "Epoch:60, Loss:0.00118441, Time:0.0187 s\n",
            "Epoch:61, Loss:0.00116222, Time:0.0183 s\n",
            "Epoch:62, Loss:0.00114081, Time:0.0185 s\n",
            "Epoch:63, Loss:0.00112013, Time:0.0184 s\n",
            "Epoch:64, Loss:0.00110016, Time:0.0186 s\n",
            "Epoch:65, Loss:0.00108085, Time:0.0186 s\n",
            "Epoch:66, Loss:0.00106217, Time:0.0261 s\n",
            "Epoch:67, Loss:0.00104410, Time:0.0195 s\n",
            "Epoch:68, Loss:0.00102660, Time:0.0187 s\n",
            "Epoch:69, Loss:0.00100965, Time:0.0185 s\n",
            "Epoch:70, Loss:0.00099323, Time:0.0190 s\n",
            "Epoch:71, Loss:0.00097730, Time:0.0186 s\n",
            "Epoch:72, Loss:0.00096185, Time:0.0197 s\n",
            "Epoch:73, Loss:0.00094686, Time:0.0181 s\n",
            "Epoch:74, Loss:0.00093231, Time:0.0185 s\n",
            "Epoch:75, Loss:0.00091817, Time:0.0182 s\n",
            "Epoch:76, Loss:0.00090443, Time:0.0185 s\n",
            "Epoch:77, Loss:0.00089108, Time:0.0246 s\n",
            "Epoch:78, Loss:0.00087810, Time:0.0204 s\n",
            "Epoch:79, Loss:0.00086547, Time:0.0186 s\n",
            "Epoch:80, Loss:0.00085318, Time:0.0195 s\n",
            "Epoch:81, Loss:0.00084122, Time:0.0186 s\n",
            "Epoch:82, Loss:0.00082957, Time:0.0186 s\n",
            "Epoch:83, Loss:0.00081822, Time:0.0192 s\n",
            "Epoch:84, Loss:0.00080716, Time:0.0187 s\n",
            "Epoch:85, Loss:0.00079639, Time:0.0188 s\n",
            "Epoch:86, Loss:0.00078588, Time:0.0184 s\n",
            "Epoch:87, Loss:0.00077563, Time:0.0184 s\n",
            "Epoch:88, Loss:0.00076563, Time:0.0270 s\n",
            "Epoch:89, Loss:0.00075588, Time:0.0187 s\n",
            "Epoch:90, Loss:0.00074635, Time:0.0188 s\n",
            "Epoch:91, Loss:0.00073705, Time:0.0186 s\n",
            "Epoch:92, Loss:0.00072797, Time:0.0192 s\n",
            "Epoch:93, Loss:0.00071909, Time:0.0185 s\n",
            "Epoch:94, Loss:0.00071042, Time:0.0196 s\n",
            "Epoch:95, Loss:0.00070195, Time:0.0188 s\n",
            "Epoch:96, Loss:0.00069366, Time:0.0190 s\n",
            "Epoch:97, Loss:0.00068556, Time:0.0188 s\n",
            "Epoch:98, Loss:0.00067763, Time:0.0193 s\n",
            "Epoch:99, Loss:0.00066988, Time:0.0259 s\n",
            "XOR prediction\n",
            "[0 0 0 0 0 0 1 1 0 1]\n",
            "[1 1 1 1 1 1 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}