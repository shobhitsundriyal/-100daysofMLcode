{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MH-github bug.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVAl73pKDW46Sq42cAtY3A"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e755e813b6a14ab29c9b844509cc3df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d2dcae779585406c94a7cdf201371398",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_81c67d4e80dc4c2d8b66ca50e068f380",
              "IPY_MODEL_e92a5feb00fa4c4b8e4d33985fec7eb6"
            ]
          }
        },
        "d2dcae779585406c94a7cdf201371398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81c67d4e80dc4c2d8b66ca50e068f380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf35d35db6074df1b49f210e60cd2eab",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffbb3eecd315425ea001389df916983f"
          }
        },
        "e92a5feb00fa4c4b8e4d33985fec7eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c2e0e45679f479a8c0a7c0128fb49e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 4.36MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc6d9648a7ba46ba86005f09601b6907"
          }
        },
        "cf35d35db6074df1b49f210e60cd2eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffbb3eecd315425ea001389df916983f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c2e0e45679f479a8c0a7c0128fb49e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc6d9648a7ba46ba86005f09601b6907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lrPwtpBWtsD",
        "outputId": "4ec27ae9-6058-4db7-8670-265c629a09d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 24.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/f3/716fd7aedf6e6808472ced6816499831f6cbeedf3814f5211db3cf991bb2/sentencepiece-0.1.93-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 47.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c2ec42976ddf4f6388f79b36911c581cda154ac39d6ff991b4540d7a5f755a14\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.93 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsqiuEKyW10D",
        "outputId": "99dbdede-958a-4e9d-a243-cdac3bc979ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "!wget \"https://machinehack-be.s3.amazonaws.com/predict_github_issues_embold_sponsored_hackathon/Embold_Participant%27s_Dataset.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAI2O7AQTB6JBT4VSA%2F20201013%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20201013T073004Z&X-Amz-Expires=172800&X-Amz-SignedHeaders=host&X-Amz-Signature=fc0c1f4968972ba262cf70ed97e74504a6e0ad78024b679839a02f8e3987eb4a\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The name is too long, 302 chars total.\n",
            "Trying to shorten...\n",
            "New name is Embold_Participant's_Dataset.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAI2O7AQTB6JBT4VSA%2F20201013%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20201013T073004Z&X-Amz-Expires=172800&X-Amz-SignedHeaders=host&X-Amz-Signatur.\n",
            "--2020-10-14 06:37:09--  https://machinehack-be.s3.amazonaws.com/predict_github_issues_embold_sponsored_hackathon/Embold_Participant%27s_Dataset.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAI2O7AQTB6JBT4VSA%2F20201013%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20201013T073004Z&X-Amz-Expires=172800&X-Amz-SignedHeaders=host&X-Amz-Signature=fc0c1f4968972ba262cf70ed97e74504a6e0ad78024b679839a02f8e3987eb4a\n",
            "Resolving machinehack-be.s3.amazonaws.com (machinehack-be.s3.amazonaws.com)... 52.219.62.32\n",
            "Connecting to machinehack-be.s3.amazonaws.com (machinehack-be.s3.amazonaws.com)|52.219.62.32|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102320961 (98M) [application/octet-stream]\n",
            "Saving to: ‘Embold_Participant's_Dataset.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAI2O7AQTB6JBT4VSA%2F20201013%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20201013T073004Z&X-Amz-Expires=172800&X-Amz-SignedHeaders=host&X-Amz-Signatur’\n",
            "\n",
            "Embold_Participant' 100%[===================>]  97.58M  13.0MB/s    in 9.2s    \n",
            "\n",
            "2020-10-14 06:37:19 (10.6 MB/s) - ‘Embold_Participant's_Dataset.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAI2O7AQTB6JBT4VSA%2F20201013%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20201013T073004Z&X-Amz-Expires=172800&X-Amz-SignedHeaders=host&X-Amz-Signatur’ saved [102320961/102320961]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-16B7CxZV_O",
        "outputId": "c032ca28-786e-4652-a845-cfdcf3eec2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "!unzip \"Embold_Participant's_Dataset.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Embold_Participant's_Dataset.zip\n",
            "   creating: Embold_Participant's_Dataset/\n",
            "  inflating: Embold_Participant's_Dataset/sample submission.csv  \n",
            "  inflating: __MACOSX/Embold_Participant's_Dataset/._sample submission.csv  \n",
            "  inflating: Embold_Participant's_Dataset/embold_train_extra.json  \n",
            "  inflating: __MACOSX/Embold_Participant's_Dataset/._embold_train_extra.json  \n",
            "  inflating: Embold_Participant's_Dataset/embold_test.json  \n",
            "  inflating: __MACOSX/Embold_Participant's_Dataset/._embold_test.json  \n",
            "  inflating: Embold_Participant's_Dataset/embold_train.json  \n",
            "  inflating: __MACOSX/Embold_Participant's_Dataset/._embold_train.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdoZVpt_ZbUX"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_json(\"Embold_Participant's_Dataset/embold_train.json\").reset_index(drop=True)\n",
        "test = pd.read_json(\"Embold_Participant's_Dataset/embold_test.json\").reset_index(drop=True)\n",
        "train_extra = pd.read_json(\"Embold_Participant's_Dataset/embold_train_extra.json\").reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chgl5SNmZ79q",
        "outputId": "9c161cfd-9454-491c-eb8c-10413bad938a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>y-zoom piano roll</td>\n",
              "      <td>a y-zoom on the piano roll would be useful.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buggy behavior in selection</td>\n",
              "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>auto update feature</td>\n",
              "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>filter out noisy endpoints in logs</td>\n",
              "      <td>i think we should stop logging requests to:\\r ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
              "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ... label\n",
              "0                                  y-zoom piano roll  ...     1\n",
              "1                        buggy behavior in selection  ...     0\n",
              "2                                auto update feature  ...     1\n",
              "3                 filter out noisy endpoints in logs  ...     1\n",
              "4  enable pid on / pid off alarm actions for ardu...  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0qqBsoCbKVL",
        "outputId": "62d8546f-4cb8-4f0a-9511-c22c82e5fff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train_extra.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>use a 8bit typeface</td>\n",
              "      <td>since this is meant to emulate some old arcade...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>implement wireless m-bus binding</td>\n",
              "      <td>_from  chris.pa...@googlemail.com  https://cod...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>add multilang support for timeago.js</td>\n",
              "      <td>currently it is only  en . \\r required to add ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>scaleway - seg-fault on shutdown</td>\n",
              "      <td>tbr  irc  creates a new scaleway instance with...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sistema de pintura: no se guardar los nuevos p...</td>\n",
              "      <td>este sp ya estaba asignado a un carro y se enc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ... label\n",
              "0                                use a 8bit typeface  ...     1\n",
              "1                   implement wireless m-bus binding  ...     1\n",
              "2               add multilang support for timeago.js  ...     1\n",
              "3                   scaleway - seg-fault on shutdown  ...     0\n",
              "4  sistema de pintura: no se guardar los nuevos p...  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfZ93hr7bVlT",
        "outputId": "38c4e814-684f-414a-f24e-11ba61d2fe86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>config question  path-specific environment var...</td>\n",
              "      <td>issue description or question\\r \\r hey @artemg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>crash indien vol</td>\n",
              "      <td>de simulator crasht als hij vol zit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unable to mine rocks</td>\n",
              "      <td>sarkasmo starting today, when i hit enter  act...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>not all whitelists are processed</td>\n",
              "      <td>create following rules... order of creation is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>add ctx menu for idafree 70 and idafree 5</td>\n",
              "      <td>associated with .dll, .dll_, .exe, .exe_, .sc,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title                                               body\n",
              "0  config question  path-specific environment var...  issue description or question\\r \\r hey @artemg...\n",
              "1                                   crash indien vol                de simulator crasht als hij vol zit\n",
              "2                               unable to mine rocks  sarkasmo starting today, when i hit enter  act...\n",
              "3                   not all whitelists are processed  create following rules... order of creation is...\n",
              "4          add ctx menu for idafree 70 and idafree 5  associated with .dll, .dll_, .exe, .exe_, .sc,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNLecbS-bXra",
        "outputId": "19cc83b4-bf8f-4911-9e85-92ef47f49adb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "from transformers import XLMRobertaTokenizer\n",
        "\n",
        "print(train.shape)\n",
        "print(train_extra.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n",
            "(300000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3Cr3K_3cXEx",
        "outputId": "a73d4615-ded7-4d12-e7f1-1ab4bc14975a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "train_df = pd.concat([train, train_extra])\n",
        "print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(450000, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>y-zoom piano roll</td>\n",
              "      <td>a y-zoom on the piano roll would be useful.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buggy behavior in selection</td>\n",
              "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>auto update feature</td>\n",
              "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>filter out noisy endpoints in logs</td>\n",
              "      <td>i think we should stop logging requests to:\\r ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
              "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ... label\n",
              "0                                  y-zoom piano roll  ...     1\n",
              "1                        buggy behavior in selection  ...     0\n",
              "2                                auto update feature  ...     1\n",
              "3                 filter out noisy endpoints in logs  ...     1\n",
              "4  enable pid on / pid off alarm actions for ardu...  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e64wibRUdNsJ",
        "outputId": "c90e144b-002d-4367-fba3-e7afe19db417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "pd.value_counts(train_df['label']).plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1853c25940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRFEcCdTfBi3"
      },
      "source": [
        "- Bug - 0\n",
        "- Feature - 1\n",
        "- Question - 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yq0RljZekBn",
        "outputId": "f02c7ee7-6825-4ba7-d965-b1c4cd5d9c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e755e813b6a14ab29c9b844509cc3df4",
            "d2dcae779585406c94a7cdf201371398",
            "81c67d4e80dc4c2d8b66ca50e068f380",
            "e92a5feb00fa4c4b8e4d33985fec7eb6",
            "cf35d35db6074df1b49f210e60cd2eab",
            "ffbb3eecd315425ea001389df916983f",
            "6c2e0e45679f479a8c0a7c0128fb49e7",
            "cc6d9648a7ba46ba86005f09601b6907"
          ]
        }
      },
      "source": [
        "xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "encoded_dict = []\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "labels_en = []\n",
        "for i, row in enumerate(train_df.iterrows()):\n",
        "  print('\\r Done {} / 450000'.format(i+1), end='')\n",
        "  encoded = xlmr_tokenizer.encode_plus(row[1].title, row[1].body, return_tensors='pt', max_length=512, padding='max_length', truncation=True)\n",
        "  input_ids.append(encoded.input_ids)\n",
        "  attention_masks.append(encoded.attention_mask)\n",
        "  labels_en.append(row[1]['label'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels_en = torch.tensor(labels_en)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e755e813b6a14ab29c9b844509cc3df4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Done 450000 / 450000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWEJ1hTdlhqP"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels_en)\n",
        "train_size = int(0.80 * 450000)\n",
        "val_size = 450000 - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vpmc0PS5SVl"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(train_dataset), batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HofOO5VcAMoW",
        "outputId": "681b1da4-852c-45df-9eb9-53ae17600e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification\n",
        "import torch\n",
        "\n",
        "xlmr_model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRy5qV9w6yWu",
        "outputId": "021e3d84-c507-42dd-a587-a44fe0f4a776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV7f--ANF47g",
        "outputId": "ef9819ed-c5df-4a7c-8bd5-b6dc9ec380c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device('cuda')\n",
        "desc = xlmr_model.to(device)\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcjF5q4uGRGr"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(xlmr_model.parameters(), lr=2e-7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V6h2aBFG0sv"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 3\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2lAVXaQJmUZ"
      },
      "source": [
        "def good_update_interval(total_iters, num_desired_updates=10):\n",
        "    '''\n",
        "    This function will try to pick an intelligent progress update interval \n",
        "    based on the magnitude of the total iterations.\n",
        "\n",
        "    Parameters:\n",
        "      `total_iters` - The number of iterations in the for-loop.\n",
        "      `num_desired_updates` - How many times we want to see an update over the \n",
        "                              course of the for-loop.\n",
        "    '''\n",
        "    # Divide the total iterations by the desired number of updates. Most likely\n",
        "    # this will be some ugly number.\n",
        "    exact_interval = total_iters / num_desired_updates\n",
        "\n",
        "    # The `round` function has the ability to round down a number to, e.g., the\n",
        "    # nearest thousandth: round(exact_interval, -3)\n",
        "    #\n",
        "    # To determine the magnitude to round to, find the magnitude of the total,\n",
        "    # and then go one magnitude below that.\n",
        "\n",
        "    # Get the order of magnitude of the total.\n",
        "    order_of_mag = len(str(total_iters)) - 1\n",
        "\n",
        "    # Our update interval should be rounded to an order of magnitude smaller. \n",
        "    round_mag = order_of_mag - 1\n",
        "\n",
        "    # Round down and cast to an int.\n",
        "    update_interval = int(round(exact_interval, -round_mag))\n",
        "\n",
        "    # Don't allow the interval to be zero!\n",
        "    if update_interval == 0:\n",
        "        update_interval = 1\n",
        "\n",
        "    return update_interval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thrxrjBgHRr4",
        "outputId": "90883dee-f6eb-4fd8-9825-4ad1e1685e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "seed = 710\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "l_train = len(train_dataloader)/8\n",
        "\n",
        "for epoch_i in range(epochs):\n",
        "\n",
        "  print('\\r Epoch: {} / {}:'.format(epoch_i, epochs),)\n",
        "\n",
        "  t0 = time.time()\n",
        "  total_traing_loss = 0\n",
        "\n",
        "  xlmr_model.train()\n",
        "\n",
        "  update_interval = good_update_interval(total_iters=len(train_dataloader))\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    print('\\r \\tBatch: {} / {}'.format(step, l_train), end='')\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    xlmr_model.zero_grad()\n",
        "\n",
        "    loss, logits = xlmr_model(\n",
        "        b_input_ids, attention_mask=b_input_mask, labels=b_labels\n",
        "    )\n",
        "\n",
        "    total_traing_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(xlmr_model.parameters(), 1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "  avg_train_loss = total_traing_loss / len(train_dataloader)\n",
        "  #training_time = format_time()\n",
        "\n",
        "  print('Evaluating')\n",
        "  xlmr_model.eval()\n",
        "\n",
        "  #validation loop to be written"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Epoch: 0 / 3:\n",
            " \tBatch: 8361 / 5625.0"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-290e10030707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlmr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIvPm99uLgoW",
        "outputId": "c69ef4bd-6876-4e38-eb46-8fd8fa9f6c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "xlmr_model(torch.tensor([325,35,56,567,31]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e5e83480dc8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxlmr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m325\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m567\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m         )\n\u001b[1;32m   1000\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;31m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;31m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extended_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;31m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mget_extended_attention_mask\u001b[0;34m(self, attention_mask, input_shape, device)\u001b[0m\n\u001b[1;32m    246\u001b[0m             raise ValueError(\n\u001b[1;32m    247\u001b[0m                 \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n\u001b[0;32m--> 248\u001b[0;31m                     \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                 )\n\u001b[1;32m    250\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong shape for input_ids (shape torch.Size([5])) or attention_mask (shape torch.Size([5]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mks_U89QYVP9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}